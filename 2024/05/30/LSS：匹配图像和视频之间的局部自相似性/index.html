

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/%E5%A4%B4%E5%83%8F1.jpg">
  <link rel="icon" href="/img/%E5%A4%B4%E5%83%8F1.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Mr.Yuan">
  <meta name="keywords" content="">
  
    <meta name="description" content="局部自相似性LSS 2007，MOSS的基础(这个才是，MOSS引用的论文出错了)">
<meta property="og:type" content="article">
<meta property="og:title" content="LSS：匹配图像和视频之间的局部自相似性">
<meta property="og:url" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/index.html">
<meta property="og:site_name" content="Blog of Mr.Yuan">
<meta property="og:description" content="局部自相似性LSS 2007，MOSS的基础(这个才是，MOSS引用的论文出错了)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/title.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig1.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig3.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig2.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/eq1.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig3.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig4.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig5.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig6.jpg">
<meta property="og:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig7.jpg">
<meta property="article:published_time" content="2024-05-30T07:30:00.000Z">
<meta property="article:modified_time" content="2024-06-03T08:01:04.557Z">
<meta property="article:author" content="Mr.Yuan">
<meta property="article:tag" content="图像匹配">
<meta property="article:tag" content="自相似">
<meta property="article:tag" content="2007">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/title.jpg">
  
  
  
  <title>LSS：匹配图像和视频之间的局部自相似性 - Blog of Mr.Yuan</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/KaTeX/0.15.2/katex.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":80,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Mr.Yuan</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/%E8%88%B9.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LSS：匹配图像和视频之间的局部自相似性"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Mr.Yuan
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-30 15:30" pubdate>
          2024年5月30日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          60 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LSS：匹配图像和视频之间的局部自相似性</h1>
            
            <div class="markdown-body">
              
              <p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/title.jpg" srcset="/img/loading.gif" lazyload alt></p>
<h1 id="matching-local-self-similarities-across-images-and-videos"><a class="markdownIt-Anchor" href="#matching-local-self-similarities-across-images-and-videos"></a> Matching Local Self-Similarities across Images and Videos</h1>
<h1 id="lss匹配图像和视频之间的局部自相似性"><a class="markdownIt-Anchor" href="#lss匹配图像和视频之间的局部自相似性"></a> LSS：匹配图像和视频之间的局部自相似性</h1>
<h1 id="摘要"><a class="markdownIt-Anchor" href="#摘要"></a> 摘要：</h1>
<p>我们提出了一种基于匹配内部自相似性的视觉实体(图像或视频)之间的相似性度量方法。跨图像(或跨视频序列)相关的是局部自相似性的内部布局(直到某些失真)，即使在每个图像/视频中产生这些局部自相似性的模式非常不同。这些内部的自相似性被紧凑的局部“自相似描述符”有效地捕获，该局部“自相似描述符”在图像/视频中以多个尺度密集地测量，同时考虑到局部和全局的几何失真。这导致了复杂视觉数据的匹配能力，包括仅使用粗略的手绘来检测真实杂乱图像中的对象，处理没有清晰边界的纹理对象，以及在没有事先学习的情况下检测杂乱视频数据中的复杂动作。我们将我们的度量与常用的基于图像和基于视频的相似性度量进行了比较，并证明了它在目标检测、检索和动作检测中的适用性。</p>
<h1 id="1-引言"><a class="markdownIt-Anchor" href="#1-引言"></a> 1 引言</h1>
<p>在许多计算机视觉任务中，确定视觉数据之间的相似性是必要的，这些任务包括对象检测和识别、动作识别、纹理分类、数据检索、跟踪、图像对齐等。执行这些任务的方法通常基于使用某些全局或局部图像属性来表示图像，并使用某些相似性度量来比较它们。</p>
<p>相关的表示和相应的相似性度量可以有很大的不同。图像通常使用基于密集光度学像素的属性或通常与兴趣点检测器一起使用的紧凑区域描述符(特征)来表示。密集属性包括原始像素强度或颜色值(整个图像、小块[25，3]或碎片[22])、纹理ﬁ[15]或其他ﬁ响应[18]。常见的紧凑区域描述符包括基于分布的描述符(例如，SIFT[13])、差分描述符(例如，局部导数[12])、使用提取的边缘的基于形状的描述符(例如，形状上下文[1])等。有关用于图像匹配的许多区域描述符的综合比较，请参见[16]。</p>
<p>尽管这些表示及其对应的测量显著不同，但它们都共享相同的基本假设–存在由两个图像(或序列)共享的共同的潜在视觉属性(即，像素颜色、强度、边缘、梯度或其他滤波器响应)，因此可以被提取并跨图像/序列进行比较。然而，这一假设可能过于严格，如图1所示。这些图像之间没有明显的图像属性共享。然而，我们可以清楚地注意到，这些都是同一对象(心脏)的实例。使这些图像相似的是，它们的局部强度模式(在每幅图像中)以类似的相对几何布局在附近的图像位置重复。换句话说，这些图像共享自我相似的局部内部布局，即使产生这些自我相似的模式并不被这些图像共享。视频序列中的自相似概念甚至比图像中的更强。例如，人们在连续的画面中穿着相同的衣服，背景往往会逐渐变化，从而在局部时空视频区域产生强烈的自相似模式。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig1.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图1.同一物体(一颗心)的这些图像不共享共同的图像属性(颜色、纹理、边缘)，但共享相似的几何布局的局部内部自相似性。</p>
</blockquote>
<p>本文提出了一种“局部自相似描述符”，它捕捉了图像/视频中局部自相似的内部几何布局，同时考虑了小的局部仿射变形。它以单一的filter方式捕捉颜色、边缘、重复图案(例如，图1中的正确图像)和复杂纹理的自相似性。一幅图像中的纹理区域可以与另一幅图像中的均匀颜色区域匹配，只要它们具有相似的空间布局。这些自相似描述符是在图像/视频数据中密集的点网格上以多个尺度进行估计的。一对图像(或一对视频序列)之间的良好匹配对应于ﬁ和这样的描述符的匹配集合-在相似的相对几何位置具有相似的描述符值，直到小的非刚性变形。这允许匹配以其他方式难以匹配的多种图像和视频类型：杂乱图像中的复杂对象被示为仅用粗略的手绘来检测；即使没有清晰的边界，也检测到相同对象的不同纹理的实例；基于单个示例剪辑，在没有预先学习的情况下检测由穿着具有不同背景的不同衣服的不同人执行的复杂动作。</p>
<p>自相似性与由互信息(MI)[23]捕获的跨图像的像素强度的统计共现的概念密切相关。或者，通常从各个图像计算和提取内部联合像素统计，然后跨图像(例如，[8，21，11])进行比较。这些方法大多局限于测量像素级测量(强度、颜色或简单的局部纹理属性)的统计共现，并且不容易扩展到更大的更有意义的模式的共现，例如图像斑块(在某些情况下，例如MI，这种限制是由于维度诅咒)。此外，统计上的共现被认为是全局的(在整个图像内)–这是一个非常强的假设，通常是无效的。其中一些方法进一步需要先前的学习阶段，有许多例子[21，11]。</p>
<p>在我们的方法中，自我相似性的衡量是局部的(在周围的图像区域内)，而不是全局的。我们的框架明确地模拟了自相似性的局部和全局几何变形。此外，我们使用斑块(在不同的尺度上)作为测量内部自相似性的基本单位(这些斑块比单个像素捕获更有意义的图像模式)。图像图案的局部自相似性也被用于纹理边缘检测[25]、对称性检测[14]和其他应用。在视频[2]中也提出了使用全局自相似性(在整个预先对准的视频帧之间)来进行步态识别。</p>
<p>最后，我们将我们的度量与几种常用的基于图像和基于视频的相似性度量进行了比较，并证明了它在目标检测、检索和动作检测中的适用性。</p>
<h1 id="2-我们的方法概述"><a class="markdownIt-Anchor" href="#2-我们的方法概述"></a> 2 我们的方法概述</h1>
<p>我们想要将“模板”图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">F(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>(或视频剪辑<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">F(x,y,t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span>)与另一图像<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>(或视频<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x,y,t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">t</span><span class="mclose">)</span></span></span></span>)进行比较。F和G不必具有相同的大小。事实上，在我们的大多数示例中，F是一个小模板(感兴趣的对象或动作的)，它在较大的G(较大的图像、较长的视频序列或图像/视频的集合)中进行搜索。</p>
<p>F和G中的“对应”点可能看起来非常不同(例如，见图3)。虽然测量图像之间的相似性可能非常复杂，但通过非常简单的相似性测量，例如简单的SSD(平方差之和)，可以很容易地揭示每个图像内的相似性，从而产生现在可以跨图像匹配的局部自相似描述符(参见图3)。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig3.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图3.相应的“自相似描述符”。我们显示了同一对象的两个图像上的几个对应点(1，2，3)，以及它们的“自相似”描述符。尽管这两幅图像的光度学特性有很大差异，但它们对应的“自相似”描述符非常相似。</p>
</blockquote>
<p>我们通过将以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>为中心的图像块与更大的周围图像区域(例如，半径为40像素)相关联来实现与每个像素<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>相关联的“局部自相似”描述符<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，从而产生局部内部“相关面”(图2.a)。我们使用术语“局部”来表示图像的一小部分(例如，5%)，而不是整个图像。然后将相关面变换为二进制对数极坐标表示(图2.a)。该表示具有两个重要的优点：(I)它为每个像素<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>产生紧凑的描述符<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。(Ii)该描述符考虑了随着距离像素q的距离而增加的位置不确定性，从而解决了局部空间仿射变形(即，比例、方向和剪切的微小变化)。最重要的是，我们的描述符考虑了额外的局部非刚性变形(见3.1)。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig2.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图2.提取本地“自相似”描述符。(A)在图像像素上。(B)视频像素。</p>
</blockquote>
<p>当匹配视频数据时，块、区域、相关表面(体积)和自相似描述符都是时空实体(图2.b)。时空视频描述符考虑了空间和时间上的局部仿射变形(因此也适应了动作速度的微小差异)。第三节详细描述了如何为图像和视频数据计算局部自相似描述符。</p>
<p>为了将整个图像/视频F匹配到G，我们在F和G中密集地计算局部自相似描述符<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。F中的所有局部描述符一起形成一个单一的全局描述符集合，该集合保持它们的相对几何位置。在G中的良好匹配对应于在G中找到相似的描述符集合-在描述符值和它们的相对几何位置上都相似(直到小的局部移位，以解决小的变形)。这在小节4中有描述。</p>
<h1 id="3-局部自相似描述子"><a class="markdownIt-Anchor" href="#3-局部自相似描述子"></a> 3 局部“自相似描述子”</h1>
<h2 id="31-空间图像描述符"><a class="markdownIt-Anchor" href="#31-空间图像描述符"></a> 3.1 空间图像描述符</h2>
<p>图2.a说明了生成与图像像素<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>相关联的自相似描述符<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的过程。使用patch颜色之间的简单平方差和(sum of square differences, SSD)(我们使用CIE<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo>∗</mo><mi>a</mi><mo>∗</mo><mi>b</mi><mo>∗</mo></mrow><annotation encoding="application/x-tex">L*a*b*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">L</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span><span class="mord">∗</span></span></span></span>空间)，将周围的图像块(通常为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5×5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span>)与以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>为中心(通常为半径40)的更大的周围图像区域进行比较。得到的距离面<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>S</mi><msub><mi>D</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">SSD_q(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>被归一化，并被变换成“相关面”<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S_q(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>：</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/eq1.jpg" srcset="/img/loading.gif" lazyload alt></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mi>a</mi><msub><mi>r</mi><mrow><mi>n</mi><mi>o</mi><mi>i</mi><mi>s</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">var_{noise}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是对应于可接受的光度变化(在颜色、照明或由于噪声)的常量，并且<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mi>a</mi><msub><mi>r</mi><mrow><mi>a</mi><mi>u</mi><mi>t</mi><mi>o</mi></mrow></msub><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">var_{auto}(q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span>考虑了补丁对比度及其图案结构，使得锐边比平滑补丁更能容忍图案变化。在我们的实现中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mi>a</mi><msub><mi>r</mi><mrow><mi>a</mi><mi>u</mi><mi>t</mi><mi>o</mi></mrow></msub><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">var_{auto}(q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mclose">)</span></span></span></span>是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>(半径为1)的非常小的邻域内的所有面片相对于以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>为中心的面片的差的最大方差。</p>
<p>然后将相关面<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S_q(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>变换为以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>为中心的对数极坐标，并将其划分为80个面元(20个角度，4个径向间隔)。我们在每个面元中选择最大的相关值。这些库中的最大值形成了与像素<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span></span></span></span>相关联的局部自相似描述符向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>的80个条目。最后，通过将其值线性拉伸到范围[0…1]来归一化该描述符向量，以保持不同斑块及其周围图像区域的图案和颜色分布的差异。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig3.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图3.相应的“自相似描述符”。我们显示了同一对象的两个图像上的几个对应点(1，2，3)，以及它们的“自相似”描述符。尽管这两幅图像的光度学特性有很大差异，但它们对应的“自相似”描述符非常相似。</p>
</blockquote>
<p>图3显示了在同一对象的两个不同外观的图像中的几个对应图像位置处计算的局部自相似描述符。注意，尽管两个图像之间的光度特性有很大差异，但它们在对应图像点的局部自相似描述符(在每个图像内分别计算)非常相似。</p>
<p>“自相似描述符”的性质和优点:</p>
<ol>
<li>自相似性被视为局部图像属性，因此是局部地(在周围图像区域内)而不是全局地(在整个图像内)测量的。这将描述符的适用范围扩展到各种具有挑战性的图像。</li>
<li>对数极坐标表示解释了自相似中的局部仿射变形。</li>
<li>通过选择每个库中的最大相关值，描述符变得对该库中最佳匹配块的准确位置不敏感(类似于用于脑信号建模的观测，例如在[19]中)。由于存储箱的大小随着半径的增加而增加，因此允许添加径向增加的非刚性变形。</li>
<li>使用斑块(在不同的尺度上)作为测量内部自相似性的基本单位，比单独的像素捕捉到更有意义的图像模式。它以单一的统一方式处理彩色区域、边缘、线条和复杂的纹理。一幅图像中的纹理区域可以与另一幅图像中的统一颜色区域或不同纹理区域匹配，只要它们具有相似的空间布局，即这些区域具有相似的形状。请注意，这是在没有任何显式分割或边缘检测的情况下完成的，因此也可以处理边界不清晰的区域(纹理或均匀)。</li>
</ol>
<h2 id="32-时空视频描述符"><a class="markdownIt-Anchor" href="#32-时空视频描述符"></a> 3.2 时空视频描述符</h2>
<p>视频序列中的自相似概念甚至比图像中的自相似概念更强。人们倾向于在连续的视频帧中穿着相同的衣服，背景场景往往会逐渐变化，导致局部时空视频区域出现强烈的自相似模式。</p>
<p>3.1节中给出的自相似描述符被扩展到时空中。斑块、区域、相关表面(体积)和自相似描述符成为时空实体(参见图2.b)。在我们的实现中，我们使用了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">5×5×1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>的补丁，与周围<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>60</mn><mo>×</mo><mn>60</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">60×60×5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">6</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span>的时空视频区域相关。由此产生的“相关体积”被转换为对数-对数-极坐标表示(空间和时间上的对数区间，但仅在空间上为极坐标区间，从而产生圆柱形的体积-参见图2.b)。所得到的自相似描述符矢量的大小为182。</p>
<h1 id="4-匹配局部描述符的全局集成"><a class="markdownIt-Anchor" href="#4-匹配局部描述符的全局集成"></a> 4 匹配局部描述符的全局集成</h1>
<p>为了将整个图像/视频F匹配到G，我们在整个F和G中密集地计算局部自相似描述符<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">d_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。这些描述符彼此相隔5个像素(在每个图像或视频帧中)被计算。F中的所有局部描述符合在一起形成一个全局“描述符集”。在G中的良好匹配对应于在G中找到相似的描述符集合-在描述符值和它们的相对几何位置上都相似(直到小的局部移位，以解决小的全局非刚性变形)。</p>
<p>然而，并不是所有的描述符都是信息性的。我们首先过滤掉非信息性描述符，即：(I)不捕捉任何局部自相似性的描述符(即，其中心块是显著的，与其周围图像/视频区域中的任何其他块不相似)，以及(Ii)在其周围区域中到处包含高自相似性的描述符(对应于大的均匀区域，即大的均匀颜色或均匀纹理的区域)。前一种类型的非信息性描述符(显著)被检测为其条目都低于某个阈值的描述符(在归一化描述符向量之前-参见第3.1节)。后一种类型的非信息性描述符(同质性)是通过采用[9]的稀疏度量来检测的。丢弃不具信息性的描述符很重要，因为这可能会在匹配阶段的稍后阶段导致不明确的匹配。注意，剩余的描述符仍然形成密集集合(比稀疏兴趣点[13，16，12]密集得多)。此外，典型兴趣点的位置不一定对应于信息性自相似描述符的位置，而均匀的斑块或边缘状的斑块可以形成信息性的自相似描述符。</p>
<p>为了在G中为F的“描述符集”找到一个好的匹配，我们使用了[3]中有效的“集匹配”算法的一个修改版本。该算法使用一个简单的概率星图模型来捕捉大量局部描述符的相对几何关系。在我们的应用中，我们将模板F中的所有描述符连接到单个这样的描述符集合中，并使用它们的搜索方法来检测G内类似的描述符集合(这允许描述符位置和值的一些局部灵活性)。我们使用L1距离上的Sigmoid函数来衡量描述符之间的相似性。集成搜索算法生成G大小的密集似然图，其对应于在G中的每个点检测F的可能性(即，根据其匹配度)。似然值高的位置被认为是在G内检测到的位置。</p>
<p>由于自相似可能在不同的尺度和不同的区域大小上出现，因此我们在多个尺度上提取自相似描述子。对于图像，我们使用高斯图像金字塔来生成这些比例；对于视频数据，我们使用时空视频金字塔。我们使用相同的参数(面片大小、周围区域等)。适用于所有比例。因此，在粗尺度上的小的5×5块的物理范围对应于在细尺度上的大的图像块的范围。为每个尺度独立地生成和搜索描述符的集合，生成其自己的似然图。为了组合来自多个尺度的信息，我们首先根据其尺度中的描述符的数量对每个对数似然图进行归一化(这些数字可能因尺度的不同而显著不同)。然后，将归一化对数似然曲面通过加权平均值与这些对数似然曲面的稀疏度[9]相对应的权重来组合。</p>
<h1 id="5-图像中的目标检测"><a class="markdownIt-Anchor" href="#5-图像中的目标检测"></a> 5 图像中的目标检测</h1>
<p>我们应用了前面几节中介绍的方法来检测杂乱图像中的感兴趣对象。给定感兴趣对象的单个示例图像(“模板图像”–例如，图4.A中的花)，我们密集地计算其Sec3.1的局部图像描述符，以生成“描述符集合”。我们使用Sec4的算法在几个杂乱的图像(例如，图4.B)中搜索这个模板集成。具有高似然值的图像位置被认为是模板图像的检测，并叠加在暗灰度图像的顶部。我们对每个图中的所有示例使用相同的阈值(但针对不同的模板使用不同的阈值)。没有涉及任何先前的图像分割，也没有任何先前的学习。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig4.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图4.对象检测。(A)单一模板图像(一朵花)。(B)将其与相应的探测进行比较的图像。高于阈值(所有图像的相同阈值)的连续似然值被显示为叠加在灰度图像上，在正确的位置显示模板的检测(红色对应于最高值)。</p>
</blockquote>
<p>我们已经将我们的算法应用于真实图像模板以及粗略的手绘模板-参见图4、5、6、7。请注意，在草绘模板的情况下，尽管草绘在颜色上是一致的，但这种全局约束并不强加于搜索的对象。这是因为自相似描述符倾向于更局部性，仅在较小的对象区域内施加自相似。(例如，我们的示例中的对象通常是每个维度的150个−200像素，而自相似描述符被约束为每个像素周围40个像素的半径)。因此，我们的方法能够检测具有全局光度可变性的相似形状的对象(例如，穿着不同颜色/纹理的裤子和衬衫的人等)。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig5.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图5.使用草图进行检测。(A)手绘模板。(B)在其他图像中检测到位置。</p>
</blockquote>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig6.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图6.使用草图进行检测。(A)手绘模板。(B)将其与相应的探测进行比较的图像。</p>
</blockquote>
<p><strong>与其他描述符和衡量标准的比较</strong>：</p>
<p>我们进一步将我们的描述符与文献[16]中评估的一些最先进的局部描述符的匹配性能进行了比较。我们选择了排名最高的局部描述符子集(并使用了[16]中的实现)。其中包括：梯度位置-方向直方图(GLOH)[16]–SIFT[13]的对数极扩展，它被证明更健壮和独特，局部形状上下文(具有方向的扩展版本[16])，以及其他四个描述符。为了将这些描述符与我们的描述符进行合理的比较，我们在边缘(在多个尺度上)密集地提取它们，以避免均匀区域和缺乏兴趣点，并使用SEC4中描述的相同的“集成匹配”方法进行组合。此外，我们将我们的方法与全局应用于模板的互信息进行了比较(我们在颜色和灰度表示上都进行了尝试)。我们在许多具有挑战性的图像对上将我们的方法与上述方法进行了比较(60多对带有花朵、心脏、和平象征等模板的图像；每个模板与多幅图像进行了比较)。如果在正确的目标处的另一图像内检测到唯一的高峰值，则宣告模板的正确检测。所有上述方法在大多数情况下都无法在另一幅图像中找到正确位置的模板，而我们的方法在86%的情况下正确地找到了模板。图7中显示了几个(有代表性的)例子。</p>
<p><img src="/2024/05/30/LSS%EF%BC%9A%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E5%92%8C%E8%A7%86%E9%A2%91%E4%B9%8B%E9%97%B4%E7%9A%84%E5%B1%80%E9%83%A8%E8%87%AA%E7%9B%B8%E4%BC%BC%E6%80%A7/fig7.jpg" srcset="/img/loading.gif" lazyload alt></p>
<blockquote>
<p>图7.与其他描述符和匹配度量的比较我们将我们的方法与其他几种最先进的局部描述子和匹配方法在60多个具有挑战性的图像对上进行了比较。所有这些方法都无法在大多数配对中找到图像2中的模板，而我们的方法在其中86%的配对中找到了正确位置的对象。每种方法都用来生成似然曲面，并显示了其最高值的90%以上的峰值。显示的是几个这样的例子(这些是代表性的结果，每个模板与图中没有显示的多个图像进行了比较)-有关更多详细信息，请参阅文本。每对图像中的对象大小相似(比例高达+/-20%)，但出于可见性目的，通常显示得更大。</p>
</blockquote>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/" class="category-chain-item">论文翻译</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D/">#图像匹配</a>
      
        <a href="/tags/%E8%87%AA%E7%9B%B8%E4%BC%BC/">#自相似</a>
      
        <a href="/tags/2007/">#2007</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LSS：匹配图像和视频之间的局部自相似性</div>
      <div>http://example.com/2024/05/30/LSS：匹配图像和视频之间的局部自相似性/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Mr.Yuan</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年5月30日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/05/30/MSFT%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%A4%9A%E6%A8%A1%E5%BC%8F%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%BB%93%E6%9E%84%E7%89%B9%E5%BE%81%E5%8F%98%E6%8D%A2/" title="MSFT：用于多模式图像匹配的多尺度结构特征变换">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">MSFT：用于多模式图像匹配的多尺度结构特征变换</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/05/29/OSS%EF%BC%9A%E5%A4%9A%E6%A8%A1%E6%80%81%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D%E7%9A%84%E8%87%AA%E7%9B%B8%E4%BC%BC%E7%89%B9%E5%BE%81/" title="OSS：多模态遥感图像匹配的自相似特征">
                        <span class="hidden-mobile">OSS：多模态遥感图像匹配的自相似特征</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    

  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <br> <span id="runtime_span"></span> <script type="text/javascript">function show_runtime(){window.setTimeout("show_runtime()",1000);X=new Date("5/1/2022 00:00:00");Y=new Date();T=(Y.getTime()-X.getTime());M=24*60*60*1000;a=T/M;A=Math.floor(a);b=(a-A)*24;B=Math.floor(b);c=(b-B)*60;C=Math.floor((b-B)*60);D=Math.floor((c-C)*60);runtime_span.innerHTML="小站已运行"+A+"天"+B+"小时"+C+"分"+D+"秒"}show_runtime();</script> 
    </div>
  
  
  
  
  {% if theme.footer.counter %}
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人</span>
  {% endif %}
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
